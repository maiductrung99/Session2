{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    #centroid: tâm của cụm\n",
    "    #members: danh sách dữ liệu trong cụm\n",
    "    def __init__(self):\n",
    "        self._centroid= None\n",
    "        self._members= []\n",
    "    def reset_members(self):\n",
    "        self._members= []\n",
    "    def add_member(self, member):\n",
    "        self._members.append(member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Member:\n",
    "    \"\"\"\n",
    "    r_d: biểu diễn tf_idf của văn bản d\n",
    "    label: newsgroup của văn bản d\n",
    "    doc_id: tên file chứa văn bản d\n",
    "    \"\"\"\n",
    "    def __init__(self, r_d, label= None, doc_id= None):\n",
    "    #Khởi tạo\n",
    "        self._r_d= r_d\n",
    "        self._label= label\n",
    "        self._doc_id= doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans:\n",
    "    \"\"\"\n",
    "    _num_cluster: số cluster đang xét\n",
    "    _cluster: list các cluster\n",
    "    _E : list các centroid\n",
    "    _S : list similarity(_r_d, _E_k)\n",
    "    \"\"\"\n",
    "    #Khởi tạo\n",
    "    def __init__(self, num_clusters):\n",
    "        self._num_clusters= num_clusters\n",
    "        self._cluster= [Cluster() for _ in range(self._num_clusters)]\n",
    "        self._E= [] # List các centroid\n",
    "        self._S= 0\n",
    "    \n",
    "    def load_data(self, data_path):\n",
    "        # Đọc dữ liệu từ file\n",
    "        def sparse_to_dense(sparse_r_d, vocab_size):\n",
    "            r_d= [0.0 for _ in range(vocab_size)]\n",
    "            indices_tfidfs = sparse_r_d.split()\n",
    "            #tách và lấy dữ liệu giữa dấu :\n",
    "            for index_tfidf in indices_tfidfs:\n",
    "                index = int(index_tfidf.split(':')[0])\n",
    "                tfidf = float(index_tfidf.split(':')[1])\n",
    "                r_d[index] = tfidf\n",
    "            return np.array(r_d)\n",
    "        with open (data_path) as f:\n",
    "            d_lines= f.read().splitlines()\n",
    "        \n",
    "        with open('./datasets/20news-bydate/words_idfs.txt') as f:\n",
    "            vocab_size= len(f.read().splitlines())\n",
    "        \n",
    "        self._data=[]\n",
    "        self._label_count = defaultdict(int)\n",
    "        for data_id, d in enumerate(d_lines):\n",
    "            features= d.split('<fff>') #lấy từng dữ liệu từ file\n",
    "            label, doc_id = int(features[0]), int(features[1])\n",
    "            self._label_count[label] += 1\n",
    "            \n",
    "            r_d = sparse_to_dense(sparse_r_d= features[2], vocab_size= vocab_size)\n",
    "            self._data.append(Member(r_d = r_d, label= label, doc_id= doc_id))\n",
    "            \n",
    "    def random_init(self, seed_value):\n",
    "    #khởi tạo random\n",
    "        d = 0\n",
    "        for cluster in self._cluster:\n",
    "            d += 1\n",
    "            np.random.seed(int(seed_value) + d)\n",
    "            temp = np.random.randint(len(self._data))\n",
    "            cluster._centroid = self._data[temp]._r_d\n",
    "            \n",
    "    def compute_similarity(self, member, centroid):\n",
    "    #đánh giá similarity\n",
    "        mem_r_d = np.array(member._r_d)\n",
    "        cen_r_d = np.array(centroid)\n",
    "        dis = np.linalg.norm(mem_r_d - cen_r_d) + 1e-12\n",
    "        return 1./dis\n",
    "    \n",
    "    def select_cluster_for(self, member):\n",
    "    #xác định cụm cho từng điểm dữ liệu (chọn cluster cho từng member theo centroid đã biết)\n",
    "        best_fit_cluster = None\n",
    "        max_similarity = -1\n",
    "        for cluster in self._cluster:\n",
    "            similarity= self.compute_similarity(member, cluster._centroid)\n",
    "            if (similarity > max_similarity):\n",
    "                max_similarity= similarity\n",
    "                best_fit_cluster= cluster\n",
    "        best_fit_cluster.add_member(member)\n",
    "        return max_similarity\n",
    "    \n",
    "    def update_centroid_of(self, cluster):\n",
    "    #xác định lại tâm (cố định member của từng cụm, tính toán lại cluster)\n",
    "        member_r_ds= [member._r_d for member in cluster._members]\n",
    "        average_r_d= np.mean(member_r_ds, axis=0)\n",
    "        sqrt_sum_sqr = np.sqrt(np.sum(average_r_d ** 2))\n",
    "        new_centroid = np.array([value / sqrt_sum_sqr for value in average_r_d])\n",
    "        \n",
    "        cluster._centroid = new_centroid\n",
    "    \n",
    "    def stopping_condition(self, criterion, threshold):\n",
    "    # Điều kiện dừng với các tham số là điều kiện và ngưỡng dừng\n",
    "        criteria = ['centroid', 'similarity', 'max_iters']\n",
    "        assert criterion in criteria\n",
    "        if criterion == 'max_iters':\n",
    "        #dừng khi số lần lặp vượt qua giới hạn max_iters\n",
    "            if self._iteration >= threshold:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        elif criterion == 'centroid':\n",
    "        #dừng khi số lượng centroid thay đổi không đáng kể\n",
    "            E_new = [list(cluster._centroid) for cluster in self._cluster]\n",
    "            E_new_minus_E = [centroid for centroid in E_new if centroid not in self._E]\n",
    "            self._E = E_new\n",
    "            if len(E_new_minus_E) <= threshold:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "        #dừng khi độ giảm lỗi phân cụm ít hơn ngưỡng\n",
    "            new_S_minus_S= self._new_S - self._S\n",
    "            self._S= self._new_S\n",
    "            if new_S_minus_S <= threshold:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "    def run(self, seed_value, criterion, threshold):\n",
    "        self.random_init(seed_value)\n",
    "        \n",
    "        #lặp cho tới điều kiện dừng ()\n",
    "        self._iteration= 0\n",
    "        while True:\n",
    "            #reset các cluster, chỉ giữ lại các centroid\n",
    "            for cluster in self._cluster:\n",
    "                cluster.reset_members()\n",
    "            self._new_S= 0\n",
    "            for member in self._data:\n",
    "                max_S= self.select_cluster_for(member)\n",
    "                self._new_S += max_S\n",
    "            for cluster in self._cluster:\n",
    "                self.update_centroid_of(cluster)\n",
    "            self._iteration += 1\n",
    "            if self.stopping_condition(criterion, threshold):\n",
    "                break\n",
    "        print ('Done')\n",
    "                \n",
    "    def compute_purity(self):\n",
    "    #đánh giá chất lượng phân cụm bằng cách tính purity\n",
    "        majority_sum= 0\n",
    "        for cluster in self._cluster:\n",
    "            member_labels = [member._label for member in cluster._members]\n",
    "            max_count = max([member_labels.count(label) for label in range(20)])\n",
    "            majority_sum += max_count\n",
    "        return majority_sum * 1. / len(self._data)\n",
    "    \n",
    "    def compute_NMI(self):\n",
    "    #đánh giá chất lượng phân cụm bằng cách tính NMI\n",
    "        I_value, H_omega, H_C, N= 0., 0., 0., len(self._data)\n",
    "        for cluster in self._cluster:\n",
    "            wk= len(cluster._members) * 1. #change int to real\n",
    "            H_omega += - wk / N * np.log10(wk / N)\n",
    "            member_labels = [member._label for member in cluster._members]\n",
    "        for label in range(20):\n",
    "            wk_cj= member_labels.count(label) * 1.\n",
    "            cj= self._label_count[label]\n",
    "            I_value += wk_cj /N * np.log10(N* wk_cj /(wk * cj) + 1e-12) #tránh err khi log số quá nhỏ\n",
    "        for label in range(20):\n",
    "            cj = self._label_count[label] * 1.\n",
    "            H_C += - cj / N * np.log10(cj / N)\n",
    "        return I_value * 2. /(H_omega + H_C) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 29.9 MiB for an array with shape (386, 10150) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e674eb16774d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./datasets/20news-bydate/words_tf_idf.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'similarity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mcompute_NMI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_NMI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_Kmeans\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcompute_NMI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-b72ec1398ba7>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, seed_value, criterion, threshold)\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_S\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmax_S\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cluster\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_centroid_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopping_condition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-b72ec1398ba7>\u001b[0m in \u001b[0;36mupdate_centroid_of\u001b[1;34m(self, cluster)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m#xác định lại tâm (cố định member của từng cụm, tính toán lại cluster)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mmember_r_ds\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_r_d\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmember\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_members\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0maverage_r_d\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember_r_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0msqrt_sum_sqr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_r_d\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mnew_centroid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msqrt_sum_sqr\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maverage_r_d\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   3332\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3334\u001b[1;33m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[0;32m   3335\u001b[0m                           out=out, **kwargs)\n\u001b[0;32m   3336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 29.9 MiB for an array with shape (386, 10150) and data type float64"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    max_Kmeans = -1\n",
    "\n",
    "    #thử 5 lần, chọn kết quả tốt nhất\n",
    "    for _ in range(5):\n",
    "        kmeans = Kmeans(20)\n",
    "        kmeans.load_data('./datasets/20news-bydate/words_tf_idf.txt')\n",
    "        kmeans.run(seed_value=20, criterion='similarity', threshold=1e5)\n",
    "        compute_NMI = kmeans.compute_NMI()\n",
    "        if (max_Kmeans < compute_NMI):\n",
    "            max_Kmeans = compute_NMI\n",
    "            result = kmeans\n",
    "    print(kmeans.compute_purity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
